{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21906,"status":"ok","timestamp":1729487397703,"user":{"displayName":"Upama Roy Chowdhury","userId":"17856602382542220487"},"user_tz":420},"id":"x2-66qP_A29h","outputId":"2af47561-1286-40f5-eb3d-1a0565f6b6c0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at content\n"]}],"source":["from google.colab import drive\n","drive.mount('content')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2101,"status":"ok","timestamp":1729669555425,"user":{"displayName":"Upama Roy Chowdhury","userId":"17856602382542220487"},"user_tz":420},"id":"2HJzJT_KMuOY","outputId":"acdb8915-1616-47f7-b512-788e2d93f847"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VvgdiGWvBVkQ"},"outputs":[],"source":["import os\n","os.chdir(\"/content/drive/MyDrive/New Work/MRI-classifier/custom_data_3D\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10866,"status":"ok","timestamp":1729669611706,"user":{"displayName":"Upama Roy Chowdhury","userId":"17856602382542220487"},"user_tz":420},"id":"20KlhUkpBrVJ","outputId":"8e835a49-a614-448c-d021-aed18d0d8d5c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: antspyx in /usr/local/lib/python3.10/dist-packages (0.5.4)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from antspyx) (2.2.2)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from antspyx) (6.0.2)\n","Requirement already satisfied: numpy<=2.0.1 in /usr/local/lib/python3.10/dist-packages (from antspyx) (1.26.4)\n","Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from antspyx) (0.14.4)\n","Requirement already satisfied: webcolors in /usr/local/lib/python3.10/dist-packages (from antspyx) (24.8.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from antspyx) (3.7.1)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from antspyx) (10.4.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from antspyx) (2.32.3)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->antspyx) (1.3.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->antspyx) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->antspyx) (4.54.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->antspyx) (1.4.7)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->antspyx) (24.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->antspyx) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->antspyx) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->antspyx) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->antspyx) (2024.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->antspyx) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->antspyx) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->antspyx) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->antspyx) (2024.8.30)\n","Requirement already satisfied: scipy!=1.9.2,>=1.8 in /usr/local/lib/python3.10/dist-packages (from statsmodels->antspyx) (1.13.1)\n","Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels->antspyx) (0.5.6)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.6->statsmodels->antspyx) (1.16.0)\n","Requirement already satisfied: SimpleITK in /usr/local/lib/python3.10/dist-packages (2.4.0)\n","Requirement already satisfied: antspynet in /usr/local/lib/python3.10/dist-packages (0.2.8)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from antspynet) (1.26.4)\n","Requirement already satisfied: tensorflow<=2.17,>=2.11 in /usr/local/lib/python3.10/dist-packages (from antspynet) (2.17.0)\n","Requirement already satisfied: antspyx>=0.4.2 in /usr/local/lib/python3.10/dist-packages (from antspynet) (0.5.4)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from antspynet) (1.5.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from antspynet) (2.32.3)\n","Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from antspynet) (0.14.4)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from antspynet) (3.7.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from antspyx>=0.4.2->antspynet) (2.2.2)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from antspyx>=0.4.2->antspynet) (6.0.2)\n","Requirement already satisfied: webcolors in /usr/local/lib/python3.10/dist-packages (from antspyx>=0.4.2->antspynet) (24.8.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from antspyx>=0.4.2->antspynet) (10.4.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.17,>=2.11->antspynet) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.17,>=2.11->antspynet) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.17,>=2.11->antspynet) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.17,>=2.11->antspynet) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.17,>=2.11->antspynet) (0.2.0)\n","Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.17,>=2.11->antspynet) (3.11.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.17,>=2.11->antspynet) (18.1.1)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.17,>=2.11->antspynet) (0.4.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.17,>=2.11->antspynet) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.17,>=2.11->antspynet) (24.1)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.17,>=2.11->antspynet) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.17,>=2.11->antspynet) (75.1.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.17,>=2.11->antspynet) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.17,>=2.11->antspynet) (2.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.17,>=2.11->antspynet) (4.12.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.17,>=2.11->antspynet) (1.16.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.17,>=2.11->antspynet) (1.64.1)\n","Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.17,>=2.11->antspynet) (2.17.0)\n","Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.17,>=2.11->antspynet) (3.4.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.17,>=2.11->antspynet) (0.37.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->antspynet) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->antspynet) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->antspynet) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->antspynet) (2024.8.30)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->antspynet) (1.3.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->antspynet) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->antspynet) (4.54.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->antspynet) (1.4.7)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->antspynet) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->antspynet) (2.8.2)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->antspynet) (1.13.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->antspynet) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->antspynet) (3.5.0)\n","Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels->antspynet) (0.5.6)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<=2.17,>=2.11->antspynet) (0.44.0)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow<=2.17,>=2.11->antspynet) (13.9.2)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow<=2.17,>=2.11->antspynet) (0.0.8)\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow<=2.17,>=2.11->antspynet) (0.13.0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->antspyx>=0.4.2->antspynet) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->antspyx>=0.4.2->antspynet) (2024.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<=2.17,>=2.11->antspynet) (3.7)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<=2.17,>=2.11->antspynet) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<=2.17,>=2.11->antspynet) (3.0.4)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow<=2.17,>=2.11->antspynet) (3.0.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow<=2.17,>=2.11->antspynet) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow<=2.17,>=2.11->antspynet) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow<=2.17,>=2.11->antspynet) (0.1.2)\n"]}],"source":["!pip install antspyx\n","!pip install SimpleITK\n","!pip install antspynet"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y3PQR5mHBhif"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from ipywidgets import interact\n","\n","# MRI related\n","import ants\n","from antspynet.utilities import brain_extraction\n","import SimpleITK as sitk"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PaMJdKHW_udy"},"outputs":[],"source":["# Load template image\n","template_img_path = \"template.nii\"\n","template_img = ants.image_read(template_img_path, reorient='IAL')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8VqHCORdCIDG"},"outputs":[],"source":["def explore_3D_array(arr: np.ndarray, cmap: str = 'gray'):\n","  def fn(SLICE):\n","    plt.figure(figsize=(7,7))\n","    plt.imshow(arr[SLICE, :, :], cmap=cmap)\n","\n","  interact(fn, SLICE=(0, arr.shape[0]-1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i7aE5Mb5KTu4"},"outputs":[],"source":["# create output save folder\n","processed_img_folder_path = \"processed_images\"\n","class_name = \"MCI\"\n","processed_img_folder_path = os.path.join(processed_img_folder_path, class_name)\n","\n","# subfolders\n","affine_registration_img_folder = \"affine_registration\"\n","bias_correction_img_folder = \"bias_correction\"\n","skull_stripping_img_folder= \"skull_stripping\"\n","\n","# subfolders paths\n","affine_registration_img_folder_path = os.path.join(processed_img_folder_path,\n","                                                   affine_registration_img_folder)\n","bias_correction_img_folder_path = os.path.join(processed_img_folder_path,\n","                                                   bias_correction_img_folder)\n","skull_stripping_img_folder_path = os.path.join(processed_img_folder_path,\n","                                                   skull_stripping_img_folder)\n","\n","# create output folders\n","folder_path_list = [affine_registration_img_folder_path,\n","                    bias_correction_img_folder_path,\n","                    skull_stripping_img_folder_path,\n","                    ]\n","\n","for subfolder_path in folder_path_list:\n","  os.makedirs(subfolder_path, exist_ok = True)"]},{"cell_type":"markdown","metadata":{"id":"l9HUT7nY_Iq6"},"source":["# Affine Registration"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EV3aQ_eTCrAo"},"outputs":[],"source":["def affine_registration(input_img, template_img):\n","  transformation = ants.registration(\n","      fixed=template_img,\n","      moving=input_img,\n","      type_of_transform='SyN',\n","      verbose=True\n","  )\n","  registered_img_ants = transformation['warpedmovout']\n","  return registered_img_ants"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cyByGyqcICy1"},"outputs":[],"source":["# for test visualization\n","# explore_3D_array(arr=img.numpy())\n","# explore_3D_array(arr=source_image.numpy())"]},{"cell_type":"markdown","metadata":{"id":"x-QCROnBEv-6"},"source":["# Bias correction"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nDHVU0jZEyn1"},"outputs":[],"source":["def explore_3D_array_bias(arr: np.ndarray, cmap: str = 'gray'):\n","  def fn(SLICE):\n","    plt.figure(figsize=(7,7))\n","    plt.imshow(arr[SLICE, :, :], cmap=cmap)\n","\n","  interact(fn, SLICE=(0, arr.shape[0]-1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aL5vKw-RE4Xo"},"outputs":[],"source":["def bias_correction(registered_img_path):\n","  # load image\n","  raw_img_sitk = sitk.ReadImage(registered_img_path, sitk.sitkFloat32)\n","  raw_img_sitk = sitk.DICOMOrient(raw_img_sitk,'RPS')\n","  raw_img_sitk_arr = sitk.GetArrayFromImage(raw_img_sitk)\n","\n","  # create head mask\n","  transformed = sitk.RescaleIntensity(raw_img_sitk, 0, 255)\n","  #transformed = sitk.TriangleThreshold(transformed, 0, 1)\n","  transformed = sitk.LiThreshold(transformed,0,1)\n","  head_mask = transformed\n","\n","  # bias correction\n","  shrinkFactor = 4\n","  inputImage = raw_img_sitk\n","  inputImage = sitk.Shrink( raw_img_sitk, [ shrinkFactor ] * inputImage.GetDimension() )\n","  maskImage = sitk.Shrink( head_mask, [ shrinkFactor ] * inputImage.GetDimension() )\n","  bias_corrector = sitk.N4BiasFieldCorrectionImageFilter()\n","  corrected = bias_corrector.Execute(inputImage, maskImage)\n","\n","  # get image corrected\n","  log_bias_field = bias_corrector.GetLogBiasFieldAsImage(raw_img_sitk)\n","  corrected_image_full_resolution = raw_img_sitk / sitk.Exp(log_bias_field)\n","\n","  return corrected_image_full_resolution"]},{"cell_type":"markdown","metadata":{"id":"HcXnrtsdQEd6"},"source":["# Skull Stripping"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1OWL9AfyZFXE"},"outputs":[],"source":["def rescale_linear(array: np.ndarray, new_min: int, new_max: int):\n","  \"\"\"Rescale an array linearly.\"\"\"\n","  minimum, maximum = np.min(array), np.max(array)\n","  m = (new_max - new_min) / (maximum - minimum)\n","  b = new_min - m * minimum\n","  return m * array + b"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HwFxVSwJQIJh"},"outputs":[],"source":["def skull_stripping(bias_corrected_image):\n","  prob_brain_mask = brain_extraction(bias_corrected_image, modality = \"t1\", verbose=True)\n","  brain_mask = ants.get_mask(prob_brain_mask, low_thresh=0.5)\n","  masked = ants.mask_image(bias_corrected_image, brain_mask)\n","  return masked"]},{"cell_type":"markdown","metadata":{"id":"RGiqjgciX1uz"},"source":["# Final loop"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5GuPr5EsX4cA","executionInfo":{"status":"ok","timestamp":1729676071281,"user_tz":420,"elapsed":4252020,"user":{"displayName":"Upama Roy Chowdhury","userId":"17856602382542220487"}},"outputId":"01c0e6b0-985a-456f-8acf-9a92eb3cd55d"},"outputs":[{"output_type":"stream","name":"stdout","text":["antsRegistration -d 3 -r [0x7a0699530968,0x7a069d42ad48,1] -m mattes[0x7a0699530968,0x7a069d42ad48,1,32,regular,0.2] -t Affine[0.25] -c 2100x1200x1200x0 -s 3x2x1x0 -f 4x2x2x1 -x [NA,NA] -m mattes[0x7a0699530968,0x7a069d42ad48,1,32] -t SyN[0.200000,3.000000,0.000000] -c [40x20x0,1e-7,8] -s 2x1x0 -f 4x2x1 -u 1 -z 1 -o [/tmp/tmply_65y8i,0x7a069de197a8,0x7a069d429e28] -x [NA,NA] --float 1 --write-composite-transform 0 -v 1\n","Brain extraction:  retrieving model weights.\n","Brain extraction:  retrieving template.\n","Brain extraction:  normalizing image to the template.\n","Brain extraction:  prediction and decoding.\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22s/step\n","Brain extraction:  renormalize probability mask to native space.\n","antsRegistration -d 3 -r [0x7a069dc034e8,0x7a069dc03968,1] -m mattes[0x7a069dc034e8,0x7a069dc03968,1,32,regular,0.2] -t Affine[0.25] -c 2100x1200x1200x0 -s 3x2x1x0 -f 4x2x2x1 -x [NA,NA] -m mattes[0x7a069dc034e8,0x7a069dc03968,1,32] -t SyN[0.200000,3.000000,0.000000] -c [40x20x0,1e-7,8] -s 2x1x0 -f 4x2x1 -u 1 -z 1 -o [/tmp/tmpvg3qx2p9,0x7a069dd5a2e8,0x7a069d126548] -x [NA,NA] --float 1 --write-composite-transform 0 -v 1\n","Brain extraction:  retrieving model weights.\n","Brain extraction:  retrieving template.\n","Brain extraction:  normalizing image to the template.\n","Brain extraction:  prediction and decoding.\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22s/step\n","Brain extraction:  renormalize probability mask to native space.\n","antsRegistration -d 3 -r [0x7a06995327a8,0x7a069dd5af48,1] -m mattes[0x7a06995327a8,0x7a069dd5af48,1,32,regular,0.2] -t Affine[0.25] -c 2100x1200x1200x0 -s 3x2x1x0 -f 4x2x2x1 -x [NA,NA] -m mattes[0x7a06995327a8,0x7a069dd5af48,1,32] -t SyN[0.200000,3.000000,0.000000] -c [40x20x0,1e-7,8] -s 2x1x0 -f 4x2x1 -u 1 -z 1 -o [/tmp/tmpq63k88p6,0x7a069dd58328,0x7a069dd5a948] -x [NA,NA] --float 1 --write-composite-transform 0 -v 1\n","Brain extraction:  retrieving model weights.\n","Brain extraction:  retrieving template.\n","Brain extraction:  normalizing image to the template.\n","Brain extraction:  prediction and decoding.\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24s/step\n","Brain extraction:  renormalize probability mask to native space.\n","antsRegistration -d 3 -r [0x7a069dc00da8,0x7a069dc01268,1] -m mattes[0x7a069dc00da8,0x7a069dc01268,1,32,regular,0.2] -t Affine[0.25] -c 2100x1200x1200x0 -s 3x2x1x0 -f 4x2x2x1 -x [NA,NA] -m mattes[0x7a069dc00da8,0x7a069dc01268,1,32] -t SyN[0.200000,3.000000,0.000000] -c [40x20x0,1e-7,8] -s 2x1x0 -f 4x2x1 -u 1 -z 1 -o [/tmp/tmp9w53ongv,0x7a069db1f048,0x7a069db1e948] -x [NA,NA] --float 1 --write-composite-transform 0 -v 1\n","Brain extraction:  retrieving model weights.\n","Brain extraction:  retrieving template.\n","Brain extraction:  normalizing image to the template.\n","Brain extraction:  prediction and decoding.\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22s/step\n","Brain extraction:  renormalize probability mask to native space.\n","antsRegistration -d 3 -r [0x7a069dd59668,0x7a069dd5a688,1] -m mattes[0x7a069dd59668,0x7a069dd5a688,1,32,regular,0.2] -t Affine[0.25] -c 2100x1200x1200x0 -s 3x2x1x0 -f 4x2x2x1 -x [NA,NA] -m mattes[0x7a069dd59668,0x7a069dd5a688,1,32] -t SyN[0.200000,3.000000,0.000000] -c [40x20x0,1e-7,8] -s 2x1x0 -f 4x2x1 -u 1 -z 1 -o [/tmp/tmp212tafp2,0x7a069dc01268,0x7a069db1fac8] -x [NA,NA] --float 1 --write-composite-transform 0 -v 1\n","Brain extraction:  retrieving model weights.\n","Brain extraction:  retrieving template.\n","Brain extraction:  normalizing image to the template.\n","Brain extraction:  prediction and decoding.\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24s/step\n","Brain extraction:  renormalize probability mask to native space.\n","antsRegistration -d 3 -r [0x7a069db1fac8,0x7a069daa1848,1] -m mattes[0x7a069db1fac8,0x7a069daa1848,1,32,regular,0.2] -t Affine[0.25] -c 2100x1200x1200x0 -s 3x2x1x0 -f 4x2x2x1 -x [NA,NA] -m mattes[0x7a069db1fac8,0x7a069daa1848,1,32] -t SyN[0.200000,3.000000,0.000000] -c [40x20x0,1e-7,8] -s 2x1x0 -f 4x2x1 -u 1 -z 1 -o [/tmp/tmpddiidro3,0x7a069ce37fa8,0x7a069d42ad48] -x [NA,NA] --float 1 --write-composite-transform 0 -v 1\n","Brain extraction:  retrieving model weights.\n","Brain extraction:  retrieving template.\n","Brain extraction:  normalizing image to the template.\n","Brain extraction:  prediction and decoding.\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22s/step\n","Brain extraction:  renormalize probability mask to native space.\n","antsRegistration -d 3 -r [0x7a069d6365e8,0x7a069d637aa8,1] -m mattes[0x7a069d6365e8,0x7a069d637aa8,1,32,regular,0.2] -t Affine[0.25] -c 2100x1200x1200x0 -s 3x2x1x0 -f 4x2x2x1 -x [NA,NA] -m mattes[0x7a069d6365e8,0x7a069d637aa8,1,32] -t SyN[0.200000,3.000000,0.000000] -c [40x20x0,1e-7,8] -s 2x1x0 -f 4x2x1 -u 1 -z 1 -o [/tmp/tmpyr45nu_y,0x7a069daa0708,0x7a069d636508] -x [NA,NA] --float 1 --write-composite-transform 0 -v 1\n","Brain extraction:  retrieving model weights.\n","Brain extraction:  retrieving template.\n","Brain extraction:  normalizing image to the template.\n","Brain extraction:  prediction and decoding.\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23s/step\n","Brain extraction:  renormalize probability mask to native space.\n","antsRegistration -d 3 -r [0x7a069de0c688,0x7a069daa1848,1] -m mattes[0x7a069de0c688,0x7a069daa1848,1,32,regular,0.2] -t Affine[0.25] -c 2100x1200x1200x0 -s 3x2x1x0 -f 4x2x2x1 -x [NA,NA] -m mattes[0x7a069de0c688,0x7a069daa1848,1,32] -t SyN[0.200000,3.000000,0.000000] -c [40x20x0,1e-7,8] -s 2x1x0 -f 4x2x1 -u 1 -z 1 -o [/tmp/tmpa3m2krww,0x7a069de0c608,0x7a069de0cde8] -x [NA,NA] --float 1 --write-composite-transform 0 -v 1\n","Brain extraction:  retrieving model weights.\n","Brain extraction:  retrieving template.\n","Brain extraction:  normalizing image to the template.\n","Brain extraction:  prediction and decoding.\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25s/step\n","Brain extraction:  renormalize probability mask to native space.\n","antsRegistration -d 3 -r [0x7a069de0c888,0x7a069de0f0c8,1] -m mattes[0x7a069de0c888,0x7a069de0f0c8,1,32,regular,0.2] -t Affine[0.25] -c 2100x1200x1200x0 -s 3x2x1x0 -f 4x2x2x1 -x [NA,NA] -m mattes[0x7a069de0c888,0x7a069de0f0c8,1,32] -t SyN[0.200000,3.000000,0.000000] -c [40x20x0,1e-7,8] -s 2x1x0 -f 4x2x1 -u 1 -z 1 -o [/tmp/tmple7h_on0,0x7a069dc01d48,0x7a069dc00e88] -x [NA,NA] --float 1 --write-composite-transform 0 -v 1\n","Brain extraction:  retrieving model weights.\n","Brain extraction:  retrieving template.\n","Brain extraction:  normalizing image to the template.\n","Brain extraction:  prediction and decoding.\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25s/step\n","Brain extraction:  renormalize probability mask to native space.\n","antsRegistration -d 3 -r [0x7a069dc01328,0x7a069de1b288,1] -m mattes[0x7a069dc01328,0x7a069de1b288,1,32,regular,0.2] -t Affine[0.25] -c 2100x1200x1200x0 -s 3x2x1x0 -f 4x2x2x1 -x [NA,NA] -m mattes[0x7a069dc01328,0x7a069de1b288,1,32] -t SyN[0.200000,3.000000,0.000000] -c [40x20x0,1e-7,8] -s 2x1x0 -f 4x2x1 -u 1 -z 1 -o [/tmp/tmpyy7vk932,0x7a069de0c888,0x7a069de0c208] -x [NA,NA] --float 1 --write-composite-transform 0 -v 1\n","Brain extraction:  retrieving model weights.\n","Brain extraction:  retrieving template.\n","Brain extraction:  normalizing image to the template.\n","Brain extraction:  prediction and decoding.\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24s/step\n","Brain extraction:  renormalize probability mask to native space.\n","antsRegistration -d 3 -r [0x7a069d429c68,0x7a069d42a988,1] -m mattes[0x7a069d429c68,0x7a069d42a988,1,32,regular,0.2] -t Affine[0.25] -c 2100x1200x1200x0 -s 3x2x1x0 -f 4x2x2x1 -x [NA,NA] -m mattes[0x7a069d429c68,0x7a069d42a988,1,32] -t SyN[0.200000,3.000000,0.000000] -c [40x20x0,1e-7,8] -s 2x1x0 -f 4x2x1 -u 1 -z 1 -o [/tmp/tmppfzd6rq0,0x7a069de1b288,0x7a069dc01268] -x [NA,NA] --float 1 --write-composite-transform 0 -v 1\n","Brain extraction:  retrieving model weights.\n","Brain extraction:  retrieving template.\n","Brain extraction:  normalizing image to the template.\n","Brain extraction:  prediction and decoding.\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22s/step\n","Brain extraction:  renormalize probability mask to native space.\n","antsRegistration -d 3 -r [0x7a069da634e8,0x7a069932c0c8,1] -m mattes[0x7a069da634e8,0x7a069932c0c8,1,32,regular,0.2] -t Affine[0.25] -c 2100x1200x1200x0 -s 3x2x1x0 -f 4x2x2x1 -x [NA,NA] -m mattes[0x7a069da634e8,0x7a069932c0c8,1,32] -t SyN[0.200000,3.000000,0.000000] -c [40x20x0,1e-7,8] -s 2x1x0 -f 4x2x1 -u 1 -z 1 -o [/tmp/tmp9tsuufvu,0x7a06992c5e68,0x7a069d42a988] -x [NA,NA] --float 1 --write-composite-transform 0 -v 1\n","Brain extraction:  retrieving model weights.\n","Brain extraction:  retrieving template.\n","Brain extraction:  normalizing image to the template.\n","Brain extraction:  prediction and decoding.\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24s/step\n","Brain extraction:  renormalize probability mask to native space.\n","antsRegistration -d 3 -r [0x7a06995916e8,0x7a069cf212e8,1] -m mattes[0x7a06995916e8,0x7a069cf212e8,1,32,regular,0.2] -t Affine[0.25] -c 2100x1200x1200x0 -s 3x2x1x0 -f 4x2x2x1 -x [NA,NA] -m mattes[0x7a06995916e8,0x7a069cf212e8,1,32] -t SyN[0.200000,3.000000,0.000000] -c [40x20x0,1e-7,8] -s 2x1x0 -f 4x2x1 -u 1 -z 1 -o [/tmp/tmpx_jwsq49,0x7a0699591bc8,0x7a06995918a8] -x [NA,NA] --float 1 --write-composite-transform 0 -v 1\n","Brain extraction:  retrieving model weights.\n","Brain extraction:  retrieving template.\n","Brain extraction:  normalizing image to the template.\n","Brain extraction:  prediction and decoding.\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24s/step\n","Brain extraction:  renormalize probability mask to native space.\n","antsRegistration -d 3 -r [0x7a06992c45c8,0x7a0699593928,1] -m mattes[0x7a06992c45c8,0x7a0699593928,1,32,regular,0.2] -t Affine[0.25] -c 2100x1200x1200x0 -s 3x2x1x0 -f 4x2x2x1 -x [NA,NA] -m mattes[0x7a06992c45c8,0x7a0699593928,1,32] -t SyN[0.200000,3.000000,0.000000] -c [40x20x0,1e-7,8] -s 2x1x0 -f 4x2x1 -u 1 -z 1 -o [/tmp/tmpymh969ly,0x7a069da634e8,0x7a069cf212e8] -x [NA,NA] --float 1 --write-composite-transform 0 -v 1\n","Brain extraction:  retrieving model weights.\n","Brain extraction:  retrieving template.\n","Brain extraction:  normalizing image to the template.\n","Brain extraction:  prediction and decoding.\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22s/step\n","Brain extraction:  renormalize probability mask to native space.\n","antsRegistration -d 3 -r [0x7a069e079348,0x7a06992c45c8,1] -m mattes[0x7a069e079348,0x7a06992c45c8,1,32,regular,0.2] -t Affine[0.25] -c 2100x1200x1200x0 -s 3x2x1x0 -f 4x2x2x1 -x [NA,NA] -m mattes[0x7a069e079348,0x7a06992c45c8,1,32] -t SyN[0.200000,3.000000,0.000000] -c [40x20x0,1e-7,8] -s 2x1x0 -f 4x2x1 -u 1 -z 1 -o [/tmp/tmp9bok33y4,0x7a06992ff488,0x7a06990c5da8] -x [NA,NA] --float 1 --write-composite-transform 0 -v 1\n","Brain extraction:  retrieving model weights.\n","Brain extraction:  retrieving template.\n","Brain extraction:  normalizing image to the template.\n","Brain extraction:  prediction and decoding.\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25s/step\n","Brain extraction:  renormalize probability mask to native space.\n","antsRegistration -d 3 -r [0x7a069902a1a8,0x7a069e079348,1] -m mattes[0x7a069902a1a8,0x7a069e079348,1,32,regular,0.2] -t Affine[0.25] -c 2100x1200x1200x0 -s 3x2x1x0 -f 4x2x2x1 -x [NA,NA] -m mattes[0x7a069902a1a8,0x7a069e079348,1,32] -t SyN[0.200000,3.000000,0.000000] -c [40x20x0,1e-7,8] -s 2x1x0 -f 4x2x1 -u 1 -z 1 -o [/tmp/tmpo9f83voo,0x7a069dea62c8,0x7a069dea5828] -x [NA,NA] --float 1 --write-composite-transform 0 -v 1\n","Brain extraction:  retrieving model weights.\n","Brain extraction:  retrieving template.\n","Brain extraction:  normalizing image to the template.\n","Brain extraction:  prediction and decoding.\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25s/step\n","Brain extraction:  renormalize probability mask to native space.\n","antsRegistration -d 3 -r [0x7a069dea5ba8,0x7a069df52d68,1] -m mattes[0x7a069dea5ba8,0x7a069df52d68,1,32,regular,0.2] -t Affine[0.25] -c 2100x1200x1200x0 -s 3x2x1x0 -f 4x2x2x1 -x [NA,NA] -m mattes[0x7a069dea5ba8,0x7a069df52d68,1,32] -t SyN[0.200000,3.000000,0.000000] -c [40x20x0,1e-7,8] -s 2x1x0 -f 4x2x1 -u 1 -z 1 -o [/tmp/tmp1njogrnl,0x7a069902a1a8,0x7a069dea62c8] -x [NA,NA] --float 1 --write-composite-transform 0 -v 1\n","Brain extraction:  retrieving model weights.\n","Brain extraction:  retrieving template.\n","Brain extraction:  normalizing image to the template.\n","Brain extraction:  prediction and decoding.\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25s/step\n","Brain extraction:  renormalize probability mask to native space.\n","antsRegistration -d 3 -r [0x7a069df52ca8,0x7a06990c5628,1] -m mattes[0x7a069df52ca8,0x7a06990c5628,1,32,regular,0.2] -t Affine[0.25] -c 2100x1200x1200x0 -s 3x2x1x0 -f 4x2x2x1 -x [NA,NA] -m mattes[0x7a069df52ca8,0x7a06990c5628,1,32] -t SyN[0.200000,3.000000,0.000000] -c [40x20x0,1e-7,8] -s 2x1x0 -f 4x2x1 -u 1 -z 1 -o [/tmp/tmp0v703dpe,0x7a069dde1608,0x7a069df52d68] -x [NA,NA] --float 1 --write-composite-transform 0 -v 1\n","Brain extraction:  retrieving model weights.\n","Brain extraction:  retrieving template.\n","Brain extraction:  normalizing image to the template.\n","Brain extraction:  prediction and decoding.\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24s/step\n","Brain extraction:  renormalize probability mask to native space.\n","antsRegistration -d 3 -r [0x7a069da5f588,0x7a069d7e9ca8,1] -m mattes[0x7a069da5f588,0x7a069d7e9ca8,1,32,regular,0.2] -t Affine[0.25] -c 2100x1200x1200x0 -s 3x2x1x0 -f 4x2x2x1 -x [NA,NA] -m mattes[0x7a069da5f588,0x7a069d7e9ca8,1,32] -t SyN[0.200000,3.000000,0.000000] -c [40x20x0,1e-7,8] -s 2x1x0 -f 4x2x1 -u 1 -z 1 -o [/tmp/tmp2a3u33i7,0x7a069d9acda8,0x7a069df52d68] -x [NA,NA] --float 1 --write-composite-transform 0 -v 1\n","Brain extraction:  retrieving model weights.\n","Brain extraction:  retrieving template.\n","Brain extraction:  normalizing image to the template.\n","Brain extraction:  prediction and decoding.\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23s/step\n","Brain extraction:  renormalize probability mask to native space.\n","antsRegistration -d 3 -r [0x7a069d9ac8a8,0x7a069d9ac048,1] -m mattes[0x7a069d9ac8a8,0x7a069d9ac048,1,32,regular,0.2] -t Affine[0.25] -c 2100x1200x1200x0 -s 3x2x1x0 -f 4x2x2x1 -x [NA,NA] -m mattes[0x7a069d9ac8a8,0x7a069d9ac048,1,32] -t SyN[0.200000,3.000000,0.000000] -c [40x20x0,1e-7,8] -s 2x1x0 -f 4x2x1 -u 1 -z 1 -o [/tmp/tmp64vpzzwc,0x7a069da5f588,0x7a069da5fca8] -x [NA,NA] --float 1 --write-composite-transform 0 -v 1\n","Brain extraction:  retrieving model weights.\n","Brain extraction:  retrieving template.\n","Brain extraction:  normalizing image to the template.\n","Brain extraction:  prediction and decoding.\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23s/step\n","Brain extraction:  renormalize probability mask to native space.\n","antsRegistration -d 3 -r [0x7a069da5fca8,0x7a069d254628,1] -m mattes[0x7a069da5fca8,0x7a069d254628,1,32,regular,0.2] -t Affine[0.25] -c 2100x1200x1200x0 -s 3x2x1x0 -f 4x2x2x1 -x [NA,NA] -m mattes[0x7a069da5fca8,0x7a069d254628,1,32] -t SyN[0.200000,3.000000,0.000000] -c [40x20x0,1e-7,8] -s 2x1x0 -f 4x2x1 -u 1 -z 1 -o [/tmp/tmpa705kilo,0x7a069da2e2a8,0x7a069d8dccc8] -x [NA,NA] --float 1 --write-composite-transform 0 -v 1\n","Brain extraction:  retrieving model weights.\n","Brain extraction:  retrieving template.\n","Brain extraction:  normalizing image to the template.\n","Brain extraction:  prediction and decoding.\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22s/step\n","Brain extraction:  renormalize probability mask to native space.\n","antsRegistration -d 3 -r [0x7a069d2ad288,0x7a069db1dd08,1] -m mattes[0x7a069d2ad288,0x7a069db1dd08,1,32,regular,0.2] -t Affine[0.25] -c 2100x1200x1200x0 -s 3x2x1x0 -f 4x2x2x1 -x [NA,NA] -m mattes[0x7a069d2ad288,0x7a069db1dd08,1,32] -t SyN[0.200000,3.000000,0.000000] -c [40x20x0,1e-7,8] -s 2x1x0 -f 4x2x1 -u 1 -z 1 -o [/tmp/tmpgy2q4elr,0x7a069d34d788,0x7a069da5fca8] -x [NA,NA] --float 1 --write-composite-transform 0 -v 1\n","Brain extraction:  retrieving model weights.\n","Brain extraction:  retrieving template.\n","Brain extraction:  normalizing image to the template.\n","Brain extraction:  prediction and decoding.\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26s/step\n","Brain extraction:  renormalize probability mask to native space.\n","antsRegistration -d 3 -r [0x7a069db1dca8,0x7a069da5fca8,1] -m mattes[0x7a069db1dca8,0x7a069da5fca8,1,32,regular,0.2] -t Affine[0.25] -c 2100x1200x1200x0 -s 3x2x1x0 -f 4x2x2x1 -x [NA,NA] -m mattes[0x7a069db1dca8,0x7a069da5fca8,1,32] -t SyN[0.200000,3.000000,0.000000] -c [40x20x0,1e-7,8] -s 2x1x0 -f 4x2x1 -u 1 -z 1 -o [/tmp/tmpftsy8o1i,0x7a0699467768,0x7a06994643a8] -x [NA,NA] --float 1 --write-composite-transform 0 -v 1\n","Brain extraction:  retrieving model weights.\n","Brain extraction:  retrieving template.\n","Brain extraction:  normalizing image to the template.\n","Brain extraction:  prediction and decoding.\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 24s/step\n","Brain extraction:  renormalize probability mask to native space.\n","antsRegistration -d 3 -r [0x7a0699464928,0x7a0699464428,1] -m mattes[0x7a0699464928,0x7a0699464428,1,32,regular,0.2] -t Affine[0.25] -c 2100x1200x1200x0 -s 3x2x1x0 -f 4x2x2x1 -x [NA,NA] -m mattes[0x7a0699464928,0x7a0699464428,1,32] -t SyN[0.200000,3.000000,0.000000] -c [40x20x0,1e-7,8] -s 2x1x0 -f 4x2x1 -u 1 -z 1 -o [/tmp/tmplha1ewp7,0x7a069ce955a8,0x7a069ce94bc8] -x [NA,NA] --float 1 --write-composite-transform 0 -v 1\n","Brain extraction:  retrieving model weights.\n","Brain extraction:  retrieving template.\n","Brain extraction:  normalizing image to the template.\n","Brain extraction:  prediction and decoding.\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22s/step\n","Brain extraction:  renormalize probability mask to native space.\n","antsRegistration -d 3 -r [0x7a069db1dca8,0x7a069d9eb388,1] -m mattes[0x7a069db1dca8,0x7a069d9eb388,1,32,regular,0.2] -t Affine[0.25] -c 2100x1200x1200x0 -s 3x2x1x0 -f 4x2x2x1 -x [NA,NA] -m mattes[0x7a069db1dca8,0x7a069d9eb388,1,32] -t SyN[0.200000,3.000000,0.000000] -c [40x20x0,1e-7,8] -s 2x1x0 -f 4x2x1 -u 1 -z 1 -o [/tmp/tmp37t6ghqh,0x7a069d591b48,0x7a0699464928] -x [NA,NA] --float 1 --write-composite-transform 0 -v 1\n","Brain extraction:  retrieving model weights.\n","Brain extraction:  retrieving template.\n","Brain extraction:  normalizing image to the template.\n","Brain extraction:  prediction and decoding.\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22s/step\n","Brain extraction:  renormalize probability mask to native space.\n"]}],"source":["# main processing loop\n","source_folder = \"custom_data_3D\"\n","source_img_folder_path = os.path.join(source_folder, class_name)\n","source_img_list = os.listdir(source_img_folder_path)\n","\n","for source_img_name in source_img_list:\n","  source_image_path = os.path.join(source_img_folder_path, source_img_name)\n","  source_image = ants.image_read(source_image_path, reorient='IAL')\n","\n","  # --------------------- perform affine registration --------------------------\n","  registered_img_ants = affine_registration(input_img = source_image,\n","                                            template_img = template_img)\n","  # save registered image\n","  registered_img_path = os.path.join(affine_registration_img_folder_path,\n","                                  source_img_name)\n","  registered_img_ants = sitk.GetImageFromArray(registered_img_ants.numpy())\n","  sitk.WriteImage(registered_img_ants, registered_img_path)\n","\n","  # --------------------- perform bias correction ------------------------------\n","  bias_corrected_image = bias_correction(registered_img_path)\n","\n","  # save bias corrected image\n","  bias_corrected_img_path = os.path.join(bias_correction_img_folder_path,\n","                                  source_img_name)\n","  sitk.WriteImage(bias_corrected_image, bias_corrected_img_path)\n","\n","  # ----------------------- perform skull stripping ----------------------------\n","  skull_stripping_input_img = ants.image_read(bias_corrected_img_path,\n","                                            reorient='IAL')\n","  skull_stripped_img = skull_stripping(bias_corrected_image =\n","                                      skull_stripping_input_img)\n","  skull_stripped_img = sitk.GetImageFromArray(skull_stripped_img.numpy())\n","\n","  # save the skull stripped image\n","  skull_stripped_img_path = os.path.join(skull_stripping_img_folder_path,\n","                                        source_img_name)\n","  sitk.WriteImage(skull_stripped_img, skull_stripped_img_path)"]}],"metadata":{"colab":{"collapsed_sections":["l9HUT7nY_Iq6","x-QCROnBEv-6","HcXnrtsdQEd6"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}